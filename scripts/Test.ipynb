{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d9ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Berlin', 'México D.F.', 'London', 'Luleå', 'Mannheim', 'Strasbourg', 'Madrid', 'Marseille', 'Tsawassen', 'Buenos Aires', 'Bern', 'Sao Paulo', 'Aachen', 'Nantes', 'Graz', 'Lille', 'Bräcke', 'München', 'Torino', 'Lisboa', 'Barcelona', 'Sevilla', 'Campinas', 'Eugene', 'Caracas', 'Rio de Janeiro', 'San Cristóbal', 'Elgin', 'Cork', 'Cowes', 'Brandenburg', 'Versailles', 'Toulouse', 'Vancouver', 'Walla Walla', 'Frankfurt a.M.', 'San Francisco', 'Barquisimeto', 'I. de Margarita', 'Portland', 'Bergamo', 'Bruxelles', 'Montréal', 'Leipzig', 'Anchorage', 'Köln', 'Paris', 'Salzburg', 'Cunewalde', 'Albuquerque', 'Reggio Emilia', 'Genève', 'Stavern', 'Boise', 'Kobenhavn', 'Lander', 'Charleroi', 'Butte', 'Münster', 'Kirkland', 'Århus', None, 'Lyon', 'Reims', 'Stuttgart', 'Oulu', 'Resende', 'Seattle', 'Helsinki', 'Warszawa']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(r'C:\\Users\\user\\innio_case_study\\data\\northwind.db')\n",
    "c_df = pd.read_sql_query(\"select * from customers\", conn)\n",
    "c_df2 = c_df[['CustomerID','City']]\n",
    "list_cities = c_df2['City'].unique().tolist()\n",
    "print(list_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "geo_data = []\n",
    "\n",
    "for city in list_cities:\n",
    "    response = requests.get(\n",
    "        f\"http://api.openweathermap.org/geo/1.0/direct?q={city}&limit=5&appid=bc2a38adcc749f24fe08205c68bb5c33\"\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        city_data = response.json()\n",
    "        if city_data:  # only if non-empty\n",
    "            for entry in city_data:\n",
    "                entry['input_city'] = city  # track original city for reference\n",
    "            geo_data.extend(city_data)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {city}\")\n",
    "\n",
    "# Create DataFrame after loop\n",
    "\n",
    "df = pd.DataFrame(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ffba7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO2 to country name mapping\n",
    "from iso3166 import countries\n",
    "\n",
    "iso_map = {country.alpha2: country.name for country in countries}\n",
    "df['country_full'] = df['country'].map(iso_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef07f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'name': 'City'})  # Rename 'name' to 'City' for consistency\n",
    "# Ensure 'City' is a string type\n",
    "df['City'] = df['City'].astype(str)     \n",
    "import unicodedata\n",
    "\n",
    "def normalize(city):\n",
    "    if pd.isna(city):\n",
    "        return None\n",
    "    # Remove accents, convert to lowercase, strip whitespace\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', city)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    ).lower().strip()\n",
    "\n",
    "c_df['City'] = c_df['City'].apply(normalize)\n",
    "df['City'] = df['City'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "93d8733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['City', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = c_df.merge(\n",
    "    df_unique.set_index(['City', 'country_full']),\n",
    "    left_on=['City', 'Country'],\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30006cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your existing merged customer + geo DataFrame\n",
    "# Make sure it contains columns: CustomerID, lat, lon\n",
    "# We'll only use rows that have valid lat/lon\n",
    "valid_geo_df = geo_df.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "# Your OpenWeather API key\n",
    "api_key = \"8de9abed422e492a58cf716b0e24caf0\"\n",
    "\n",
    "# Store all API responses\n",
    "weather_data = []\n",
    "\n",
    "# Loop through each customer with lat/lon\n",
    "for idx, row in valid_geo_df.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    customer_id = row['CustomerID']\n",
    "\n",
    "    # Build the One Call 3.0 API URL (current + forecast)\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&appid={api_key}&units=metric\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Track which customer this response belongs to\n",
    "            result['CustomerID'] = customer_id\n",
    "            result['lat'] = lat\n",
    "            result['lon'] = lon\n",
    "\n",
    "            # Add the API result to our list\n",
    "            weather_data.append(result)\n",
    "        else:\n",
    "            print(f\"[ERROR] Failed for CustomerID {customer_id}: Status {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[EXCEPTION] CustomerID {customer_id}: {str(e)}\")\n",
    "\n",
    "# Convert all responses into a DataFrame\n",
    "# This flattens nested JSON (e.g., current.temp, current.weather[0].description)\n",
    "weather_df = pd.json_normalize(weather_data)\n",
    "\n",
    "# Preview the key weather data\n",
    "print(weather_df[['CustomerID', 'lat', 'lon', 'current.temp', 'current.weather']].head())\n",
    "\n",
    "# OPTIONAL: Save to CSV or merge with geo_df\n",
    "# weather_df.to_csv(\"customer_weather_data.csv\", index=False)\n",
    "\n",
    "# OPTIONAL: Merge weather info back to original customer data\n",
    "#merged_df = geo_df.merge(weather_df, on=['CustomerID', 'lat', 'lon'], how='left')\n",
    "#Matbe not rquired, depends on your next steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ef7837f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7ade496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = f\"https://api.openweathermap.org/data/3.0/onecall?lat=52.517037&lon=13.388860&appid=appid=bc2a38adcc749f24fe08205c68bb5c33&units=metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9104d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [401]>\n"
     ]
    }
   ],
   "source": [
    "res1 = requests.get(res1)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86df8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

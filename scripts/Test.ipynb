{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86d9ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Berlin', 'México D.F.', 'London', 'Luleå', 'Mannheim', 'Strasbourg', 'Madrid', 'Marseille', 'Tsawassen', 'Buenos Aires', 'Bern', 'Sao Paulo', 'Aachen', 'Nantes', 'Graz', 'Lille', 'Bräcke', 'München', 'Torino', 'Lisboa', 'Barcelona', 'Sevilla', 'Campinas', 'Eugene', 'Caracas', 'Rio de Janeiro', 'San Cristóbal', 'Elgin', 'Cork', 'Cowes', 'Brandenburg', 'Versailles', 'Toulouse', 'Vancouver', 'Walla Walla', 'Frankfurt a.M.', 'San Francisco', 'Barquisimeto', 'I. de Margarita', 'Portland', 'Bergamo', 'Bruxelles', 'Montréal', 'Leipzig', 'Anchorage', 'Köln', 'Paris', 'Salzburg', 'Cunewalde', 'Albuquerque', 'Reggio Emilia', 'Genève', 'Stavern', 'Boise', 'Kobenhavn', 'Lander', 'Charleroi', 'Butte', 'Münster', 'Kirkland', 'Århus', None, 'Lyon', 'Reims', 'Stuttgart', 'Oulu', 'Resende', 'Seattle', 'Helsinki', 'Warszawa']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(r'C:\\Users\\user\\innio_case_study\\data\\northwind.db')\n",
    "c_df = pd.read_sql_query(\"select * from customers\", conn)\n",
    "c_df2 = c_df[['CustomerID','City']]\n",
    "list_cities = c_df2['City'].unique().tolist()\n",
    "print(list_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "geo_data = []\n",
    "\n",
    "for city in list_cities:\n",
    "    response = requests.get(\n",
    "        f\"http://api.openweathermap.org/geo/1.0/direct?q={city}&limit=5&appid=bc2a38adcc749f24fe08205c68bb5c33\"\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        city_data = response.json()\n",
    "        if city_data:  # only if non-empty\n",
    "            for entry in city_data:\n",
    "                entry['input_city'] = city  # track original city for reference\n",
    "            geo_data.extend(city_data)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {city}\")\n",
    "\n",
    "# Create DataFrame after loop\n",
    "\n",
    "df = pd.DataFrame(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ffba7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISO2 to country name mapping\n",
    "from iso3166 import countries\n",
    "\n",
    "iso_map = {country.alpha2: country.name for country in countries}\n",
    "df['country_full'] = df['country'].map(iso_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef07f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'name': 'City'})  # Rename 'name' to 'City' for consistency\n",
    "# Ensure 'City' is a string type\n",
    "df['City'] = df['City'].astype(str)     \n",
    "import unicodedata\n",
    "\n",
    "def normalize(city):\n",
    "    if pd.isna(city):\n",
    "        return None\n",
    "    # Remove accents, convert to lowercase, strip whitespace\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', city)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    ).lower().strip()\n",
    "\n",
    "c_df['City'] = c_df['City'].apply(normalize)\n",
    "df['City'] = df['City'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "93d8733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df.drop_duplicates(subset=['City', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b150bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = c_df.merge(\n",
    "    df_unique.set_index(['City', 'country_full']),\n",
    "    left_on=['City', 'Country'],\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "30006cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Failed for CustomerID ALFKI: Status 401\n",
      "[ERROR] Failed for CustomerID BERGS: Status 401\n",
      "[ERROR] Failed for CustomerID BLAUS: Status 401\n",
      "[ERROR] Failed for CustomerID BLONP: Status 401\n",
      "[ERROR] Failed for CustomerID BOLID: Status 401\n",
      "[ERROR] Failed for CustomerID BONAP: Status 401\n",
      "[ERROR] Failed for CustomerID CACTU: Status 401\n",
      "[ERROR] Failed for CustomerID CHOPS: Status 401\n",
      "[ERROR] Failed for CustomerID COMMI: Status 401\n",
      "[ERROR] Failed for CustomerID DRACD: Status 401\n",
      "[ERROR] Failed for CustomerID DUMON: Status 401\n",
      "[ERROR] Failed for CustomerID ERNSH: Status 401\n",
      "[ERROR] Failed for CustomerID FAMIA: Status 401\n",
      "[ERROR] Failed for CustomerID FISSA: Status 401\n",
      "[ERROR] Failed for CustomerID FOLIG: Status 401\n",
      "[ERROR] Failed for CustomerID FOLKO: Status 401\n",
      "[ERROR] Failed for CustomerID FRANK: Status 401\n",
      "[ERROR] Failed for CustomerID FRANR: Status 401\n",
      "[ERROR] Failed for CustomerID FRANS: Status 401\n",
      "[ERROR] Failed for CustomerID GALED: Status 401\n",
      "[ERROR] Failed for CustomerID GOURL: Status 401\n",
      "[ERROR] Failed for CustomerID HANAR: Status 401\n",
      "[ERROR] Failed for CustomerID HUNGO: Status 401\n",
      "[ERROR] Failed for CustomerID KOENE: Status 401\n",
      "[ERROR] Failed for CustomerID LACOR: Status 401\n",
      "[ERROR] Failed for CustomerID LAMAI: Status 401\n",
      "[ERROR] Failed for CustomerID LAUGB: Status 401\n",
      "[ERROR] Failed for CustomerID MAGAA: Status 401\n",
      "[ERROR] Failed for CustomerID MEREP: Status 401\n",
      "[ERROR] Failed for CustomerID MORGK: Status 401\n",
      "[ERROR] Failed for CustomerID OCEAN: Status 401\n",
      "[ERROR] Failed for CustomerID PARIS: Status 401\n",
      "[ERROR] Failed for CustomerID PICCO: Status 401\n",
      "[ERROR] Failed for CustomerID QUEDE: Status 401\n",
      "[ERROR] Failed for CustomerID QUEEN: Status 401\n",
      "[ERROR] Failed for CustomerID QUICK: Status 401\n",
      "[ERROR] Failed for CustomerID RANCH: Status 401\n",
      "[ERROR] Failed for CustomerID RICAR: Status 401\n",
      "[ERROR] Failed for CustomerID ROMEY: Status 401\n",
      "[ERROR] Failed for CustomerID SANTG: Status 401\n",
      "[ERROR] Failed for CustomerID SPECD: Status 401\n",
      "[ERROR] Failed for CustomerID SUPRD: Status 401\n",
      "[ERROR] Failed for CustomerID TOMSP: Status 401\n",
      "[ERROR] Failed for CustomerID TRADH: Status 401\n",
      "[ERROR] Failed for CustomerID VICTE: Status 401\n",
      "[ERROR] Failed for CustomerID VINET: Status 401\n",
      "[ERROR] Failed for CustomerID WANDK: Status 401\n",
      "[ERROR] Failed for CustomerID WARTH: Status 401\n",
      "[ERROR] Failed for CustomerID WELLI: Status 401\n",
      "[ERROR] Failed for CustomerID WILMK: Status 401\n",
      "[ERROR] Failed for CustomerID WOLZA: Status 401\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['CustomerID', 'lat', 'lon', 'current.temp', 'current.weather'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[130]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m weather_df = pd.json_normalize(weather_data)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Preview the key weather data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mweather_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCustomerID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlon\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcurrent.temp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcurrent.weather\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.head())\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# OPTIONAL: Save to CSV or merge with geo_df\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# weather_df.to_csv(\"customer_weather_data.csv\", index=False)\u001b[39;00m\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# OPTIONAL: Merge weather info back to original customer data\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m#merged_df = geo_df.merge(weather_df, on=['CustomerID', 'lat', 'lon'], how='left')\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\innio_case_study\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\innio_case_study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\innio_case_study\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['CustomerID', 'lat', 'lon', 'current.temp', 'current.weather'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your existing merged customer + geo DataFrame\n",
    "# Make sure it contains columns: CustomerID, lat, lon\n",
    "# We'll only use rows that have valid lat/lon\n",
    "valid_geo_df = geo_df.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "# Your OpenWeather API key\n",
    "api_key = \"8de9abed422e492a58cf716b0e24caf0\"\n",
    "\n",
    "# Store all API responses\n",
    "weather_data = []\n",
    "\n",
    "# Loop through each customer with lat/lon\n",
    "for idx, row in valid_geo_df.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "    customer_id = row['CustomerID']\n",
    "\n",
    "    # Build the One Call 3.0 API URL (current + forecast)\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/onecall?lat={lat}&lon={lon}&appid={api_key}&units=metric\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            \n",
    "            # Track which customer this response belongs to\n",
    "            result['CustomerID'] = customer_id\n",
    "            result['lat'] = lat\n",
    "            result['lon'] = lon\n",
    "\n",
    "            # Add the API result to our list\n",
    "            weather_data.append(result)\n",
    "        else:\n",
    "            print(f\"[ERROR] Failed for CustomerID {customer_id}: Status {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[EXCEPTION] CustomerID {customer_id}: {str(e)}\")\n",
    "\n",
    "# Convert all responses into a DataFrame\n",
    "# This flattens nested JSON (e.g., current.temp, current.weather[0].description)\n",
    "weather_df = pd.json_normalize(weather_data)\n",
    "\n",
    "# Preview the key weather data\n",
    "print(weather_df[['CustomerID', 'lat', 'lon', 'current.temp', 'current.weather']].head())\n",
    "\n",
    "# OPTIONAL: Save to CSV or merge with geo_df\n",
    "# weather_df.to_csv(\"customer_weather_data.csv\", index=False)\n",
    "\n",
    "# OPTIONAL: Merge weather info back to original customer data\n",
    "#merged_df = geo_df.merge(weather_df, on=['CustomerID', 'lat', 'lon'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ef7837f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7ade496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = f\"https://api.openweathermap.org/data/3.0/onecall?lat=52.517037&lon=13.388860&appid=appid=bc2a38adcc749f24fe08205c68bb5c33&units=metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9104d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [401]>\n"
     ]
    }
   ],
   "source": [
    "res1 = requests.get(res1)\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86df8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
